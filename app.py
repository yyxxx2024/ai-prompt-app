import streamlit as st
from openai import OpenAI
import base64

# 1. é¡µé¢åŸºæœ¬è®¾ç½® (å®½å±æ¨¡å¼ + å›¾æ ‡)
st.set_page_config(page_title="ğŸ¨ AI æç¤ºè¯é­”æ³•å¸ˆ Pro", page_icon="ğŸª„", layout="centered")
st.title("âœ¨ AI æç¤ºè¯é­”æ³•å¸ˆ Pro")

# --- ğŸ› ï¸ è¾…åŠ©å‡½æ•°ï¼šå›¾ç‰‡è½¬ Base64 ---
def encode_image(uploaded_file):
    return base64.b64encode(uploaded_file.getvalue()).decode('utf-8')

# --- ğŸ” ä¾§è¾¹æ ï¼šæ ¸å¿ƒè®¾ç½®åŒº ---
with st.sidebar:
    st.header("ğŸ” èº«ä»½éªŒè¯")
    
    # ä»äº‘ç«¯ secrets è·å–å¯†ç å’Œ Key
    SYSTEM_PASSWORD = st.secrets.get("APP_PASSWORD", None)
    SYSTEM_API_KEY = st.secrets.get("API_KEY", None)

    api_key = None
    user_password = st.text_input("è®¿é—®å¯†ç ", type="password", placeholder="è¾“å…¥å¯†ç è‡ªåŠ¨åŠ è½½ Key")

    # å¯†ç éªŒè¯é€»è¾‘
    if SYSTEM_PASSWORD and user_password == SYSTEM_PASSWORD:
        api_key = SYSTEM_API_KEY
        st.success("âœ… å¯†ç æ­£ç¡®ï¼")
    else:
        if user_password: st.error("âŒ å¯†ç é”™è¯¯")
        st.caption("æˆ–æ‰‹åŠ¨è¾“å…¥ API Keyï¼š")
        api_key = st.text_input("Key", type="password", label_visibility="collapsed")

    st.markdown("---")
    st.header("âš™ï¸ API è®¾ç½® (æ¨èç”¨ä¸­è½¬)")
    
    # ğŸ‘‡ è¿™é‡Œæ˜¯å…³é”®ï¼šå…è®¸åŒæ—¶é…ç½®ä¸¤ä¸ªæ¨¡å‹ï¼Œæ–¹ä¾¿æ¥å›åˆ‡æ¢
    base_url = st.text_input("API åœ°å€ (Base URL)", value="https://api.deepseek.com", help="å¦‚æœæ˜¯ä¸­è½¬å•†ï¼Œé€šå¸¸å¡« https://api.xxx.com/v1")
    
    st.caption("ğŸ“ **æ–‡æœ¬ç”Ÿæˆæ¨¡å‹** (æ¨è DeepSeek)")
    text_model = st.text_input("Text Model", value="deepseek-chat", label_visibility="collapsed")
    
    st.caption("ğŸ–¼ï¸ **å›¾ç‰‡åæ¨æ¨¡å‹** (æ¨è GPT-4o-mini)")
    vision_model = st.text_input("Vision Model", value="gpt-4o-mini", label_visibility="collapsed")
    
    st.info("ğŸ’¡ **çœé’±æ”»ç•¥**ï¼š\næ‰¾ä¸€ä¸ªæ”¯æŒ DeepSeek å’Œ OpenAI çš„ä¸­è½¬å•†ï¼Œå¡«å…¥ç»Ÿä¸€çš„ API åœ°å€ï¼Œå°±èƒ½åŒæ—¶ç”¨è¿™ä¸¤ä¸ªåŠŸèƒ½äº†ï¼")

# --- ğŸ—ï¸ åŠŸèƒ½æ ‡ç­¾é¡µ ---
tab1, tab2 = st.tabs(["ğŸ“ æ–‡æœ¬ç”Ÿæˆæç¤ºè¯", "ğŸ–¼ï¸ å›¾ç‰‡åæ¨æç¤ºè¯ (çœ‹å›¾)"])

# ==========================================
# ğŸ‘‰ æ ‡ç­¾ 1ï¼šæ–‡æœ¬ç”Ÿæˆ (DeepSeek/MJ)
# ==========================================
with tab1:
    st.subheader("âœï¸ æè¿°ç”»é¢ï¼Œç”Ÿæˆ Prompt")
    user_input = st.text_area("ä½ æƒ³ç”»ä»€ä¹ˆï¼Ÿ(æ”¯æŒä¸­æ–‡)", height=100, placeholder="ä¾‹å¦‚ï¼šä¸€åº§æµ·è¾¹çš„ç™½è‰²ç¾æœ¯é¦†ï¼Œæ‰å“ˆÂ·å“ˆè¿ªå¾·é£æ ¼ï¼Œæµçº¿å‹è®¾è®¡...")

    # æ¨¡å¼é€‰æ‹©
    col1, col2 = st.columns(2)
    with col1:
        ratio = st.selectbox("ç”»å¹…æ¯”ä¾‹", ["--ar 16:9 (æ¨ªå±)", "--ar 9:16 (æ‰‹æœº)", "--ar 1:1 (æ–¹å½¢)", "--ar 4:3 (æ ‡å‡†)", "--ar 3:2 (æ‘„å½±)"])
    with col2:
        mode = st.selectbox("ç”Ÿæˆæ¨¡å¼", [
            "å»ºç­‘è®¾è®¡ (Architecture)",            # ğŸ—ï¸ ä½ çš„å»ºç­‘éœ€æ±‚
            "æ ‡å‡†æ¨¡å¼ (MJ/SDé€šç”¨)",               # é€šç”¨
            "è‡ªç„¶è¯­è¨€æ¨¡å¼ (Google/Nano Banana 2)", # Google/DALL-E
            "æç®€æ¨¡å¼ (MJ V6ä¸“ç”¨)",               # çœ token
            "å†™å®æ‘„å½± (Photo)",                   # äººåƒé£æ™¯
            "äºŒæ¬¡å…ƒé­”æ³• (Niji)",                  # åŠ¨æ¼«
            "3D æ¸²æŸ“ (3D)"                        # è®¾è®¡ç›²ç›’
        ])

    # é«˜çº§é€‰é¡¹ (æŠ˜å )
    with st.expander("ğŸ¨ é«˜çº§é€‰é¡¹ (å…‰çº¿ã€è§†è§’ã€æè´¨)"):
        c1, c2, c3 = st.columns(3)
        with c1: lighting = st.selectbox("ğŸ’¡ å…‰çº¿", ["ä¸æŒ‡å®š", "è‡ªç„¶å…‰", "é»„é‡‘æ—¶åˆ»", "ç”µå½±çº§å¸ƒå…‰", "é˜´å¤©æ¼«å°„", "èµ›åšéœ“è™¹"])
        with c2: camera = st.selectbox("ğŸ“· è§†è§’", ["ä¸æŒ‡å®š", "ä¸€ç‚¹é€è§†", "å¹¿è§’å®å¤§", "é¸Ÿç°å›¾", "äººè§†è§’åº¦", "å¾®è·"])
        with c3: material = st.selectbox("ğŸ§¶ æè´¨", ["ä¸æŒ‡å®š", "æ··å‡åœŸä¸ç»ç’ƒ", "æœ¨è´¨çº¹ç†", "è™šå¹»å¼•æ“5", "V-Rayæ¸²æŸ“", "ç£¨ç ‚è´¨æ„Ÿ"])
        negative_prompt = st.text_input("ğŸš« è´Ÿé¢æç¤ºè¯", value="text, watermark, blurry, low quality, bad anatomy, ugly")

    # ç³»ç»Ÿæç¤ºè¯é€»è¾‘ (AIå¤§è„‘)
    system_prompts = {
        "å»ºç­‘è®¾è®¡ (Architecture)": "Translate to English. Target: High-end Architectural Visualization. Add tags: architectural photography, ArchDaily style, Dezeen style, modern architecture, photorealistic, 8k, highly detailed, dramatic lighting, V-Ray render, clean lines, geometric structure.",
        "æ ‡å‡†æ¨¡å¼ (MJ/SDé€šç”¨)": "Translate to English. Output purely as a list of comma-separated keywords (tags). Focus on visual descriptors, quality tags.",
        "è‡ªç„¶è¯­è¨€æ¨¡å¼ (Google/Nano Banana 2)": "You are an expert for Google Imagen 2. Translate to a rich, descriptive, natural English paragraph. Do NOT use comma-separated tags. Write fluid sentences. Start with 'A photorealistic image of...'.",
        "æç®€æ¨¡å¼ (MJ V6ä¸“ç”¨)": "Translate to English. Keep it extremely concise. Subject + Action + Style + Lighting. Comma separated.",
        "å†™å®æ‘„å½± (Photo)": "Translate to English. Target: Photorealism. Add tags: shot on Sony A7RIV, 85mm lens, f/1.8, cinematic lighting, hyper-realistic, 8k, raw photo.",
        "äºŒæ¬¡å…ƒé­”æ³• (Niji)": "Translate to English. Target model: Niji Journey. Add tags: anime style, cel shading, studio ghibli, vibrant colors, highly detailed.",
        "3D æ¸²æŸ“ (3D)": "Translate to English. Target: 3D Render. Add tags: octane render, blender, c4d, unreal engine 5, 8k resolution, 3d masterpiece."
    }

    if st.button("ğŸš€ å¼€å§‹ç”Ÿæˆ (æ–‡æœ¬)", type="primary"):
        if not api_key: st.error("è¯·å…ˆéªŒè¯å¯†ç æˆ–è¾“å…¥ Keyï¼"); st.stop()
        
        try:
            client = OpenAI(api_key=api_key, base_url=base_url)
            
            # æ‹¼æ¥é«˜çº§é€‰é¡¹
            details = []
            if lighting != "ä¸æŒ‡å®š": details.append(f"å…‰çº¿ï¼š{lighting}")
            if camera != "ä¸æŒ‡å®š": details.append(f"è§†è§’ï¼š{camera}")
            if material != "ä¸æŒ‡å®š": details.append(f"æè´¨ï¼š{material}")
            full_req = f"ç”¨æˆ·æè¿°ï¼š{user_input}ã€‚é¢å¤–è¦æ±‚ï¼š{' '.join(details)}"

            with st.spinner(f'AI ({text_model}) æ­£åœ¨æ„æ€...'):
                response = client.chat.completions.create(
                    model=text_model, # ä½¿ç”¨ä¾§è¾¹æ è®¾ç½®çš„æ–‡æœ¬æ¨¡å‹
                    messages=[
                        {"role": "system", "content": system_prompts[mode]},
                        {"role": "user", "content": full_req}
                    ],
                    temperature=0.7
                )
                
                ai_result = response.choices[0].message.content
                final_output = f"{ai_result} {ratio.split(' ')[0]} {ratio.split(' ')[1]}"
                if negative_prompt and "è‡ªç„¶è¯­è¨€" not in mode:
                    final_output += f" --no {negative_prompt}"

            st.success("ç”ŸæˆæˆåŠŸï¼")
            st.markdown("### âœ… ç»“æœ (å³ä¸Šè§’å¤åˆ¶)")
            st.code(final_output, language="text", wrap_lines=True)

        except Exception as e:
            st.error(f"å‡ºé”™ï¼š{str(e)}")

# ==========================================
# ğŸ‘‰ æ ‡ç­¾ 2ï¼šå›¾ç‰‡åæ¨ (GPT-4o/Claude)
# ==========================================
with tab2:
    st.subheader("ğŸ–¼ï¸ ä¸Šä¼ å›¾ç‰‡ï¼Œåæ¨ Prompt")
    st.info(f"ğŸ’¡ å½“å‰ä½¿ç”¨æ¨¡å‹ï¼š**{vision_model}** (è¯·ç¡®ä¿ä½ çš„ Key æ”¯æŒè¯¥æ¨¡å‹)")

    uploaded_file = st.file_uploader("æ‹–å…¥å‚è€ƒå›¾", type=["jpg", "png", "jpeg"])
    reverse_mode = st.radio("è¾“å‡ºæ ¼å¼", ["MJ æ ‡ç­¾æ ¼å¼ (é€—å·åˆ†éš”)", "è‡ªç„¶è¯­è¨€æè¿° (å†™ä½œæ–‡)"], horizontal=True)

    if uploaded_file and st.button("ğŸ” å¼€å§‹åæ¨", type="primary"):
        if not api_key: st.error("è¯·å…ˆéªŒè¯å¯†ç ï¼"); st.stop()
        
        try:
            client = OpenAI(api_key=api_key, base_url=base_url)
            base64_image = encode_image(uploaded_file)
            
            # å®šä¹‰åæ¨æŒ‡ä»¤
            if "æ ‡ç­¾" in reverse_mode:
                prompt_text = "åˆ†æè¿™å¼ å›¾çš„ä¸»ä½“ã€é£æ ¼ã€å…‰å½±ã€æè´¨ã€‚ç›´æ¥è¾“å‡ºè‹±æ–‡å…³é”®è¯ï¼Œç”¨é€—å·åˆ†éš”ã€‚"
            else:
                prompt_text = "è¯¦ç»†æè¿°è¿™å¼ å›¾ç‰‡ï¼ŒåŒ…æ‹¬ä¸»ä½“ã€ç¯å¢ƒã€å…‰å½±å’Œé£æ ¼ã€‚è¯·è¾“å‡ºä¸€æ®µé€šé¡ºä¼˜ç¾çš„è‹±æ–‡æè¿°ï¼ˆé€‚åˆ DALL-E 3 æˆ– Google GenAIï¼‰ã€‚"

            with st.spinner(f'AI ({vision_model}) æ­£åœ¨è§‚å¯Ÿå›¾ç‰‡...'):
                response = client.chat.completions.create(
                    model=vision_model, # ä½¿ç”¨ä¾§è¾¹æ è®¾ç½®çš„è§†è§‰æ¨¡å‹
                    messages=[
                        {
                            "role": "user",
                            "content": [
                                {"type": "text", "text": prompt_text},
                                {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}}
                            ]
                        }
                    ],
                    max_tokens=500
                )
            
            result_text = response.choices[0].message.content
            
            c1, c2 = st.columns([1, 2])
            with c1: st.image(uploaded_file, caption="åŸå›¾", use_container_width=True)
            with c2:
                st.success("åæ¨å®Œæˆï¼")
                st.code(result_text, language="text", wrap_lines=True)

        except Exception as e:
            st.error("âŒ å¤±è´¥äº†")
            st.error(f"é”™è¯¯è¯¦æƒ…ï¼š{str(e)}")
            st.warning("å¸¸è§åŸå› ï¼šä½ ä½¿ç”¨çš„ API Key ä¸æ”¯æŒè§†è§‰æ¨¡å‹ï¼Œæˆ–è€… Base URL å¡«çš„æ˜¯ DeepSeek å®˜æ–¹åœ°å€ï¼ˆDeepSeek æš‚ä¸æ”¯æŒçœ‹å›¾ï¼‰ã€‚å»ºè®®ä½¿ç”¨æ”¯æŒ GPT-4o-mini çš„ä¸­è½¬æœåŠ¡ã€‚")

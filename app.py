import streamlit as st
from openai import OpenAI
import base64

# 1. é¡µé¢è®¾ç½®
st.set_page_config(page_title="ğŸ¨ AI æç¤ºè¯é­”æ³•å¸ˆ Pro", page_icon="ğŸª„", layout="centered")
st.title("âœ¨ AI æç¤ºè¯é­”æ³•å¸ˆ Pro")

# --- ğŸ› ï¸ è¾…åŠ©å‡½æ•° ---
def encode_image(uploaded_file):
    return base64.b64encode(uploaded_file.getvalue()).decode('utf-8')

# --- ğŸ” ä¾§è¾¹æ ï¼šæ ¸å¿ƒè®¾ç½®åŒº ---
with st.sidebar:
    st.header("ğŸ” èº«ä»½éªŒè¯")
    
    SYSTEM_PASSWORD = st.secrets.get("APP_PASSWORD", None)
    SYSTEM_API_KEY = st.secrets.get("API_KEY", None)
    api_key = None
    
    user_password = st.text_input("ğŸ”‘ è®¿é—®å¯†ç ", type="password", placeholder="è¾“å…¥å¯†ç ï¼Œè‡ªåŠ¨åŠ è½½ Key")

    if SYSTEM_PASSWORD and user_password == SYSTEM_PASSWORD:
        api_key = SYSTEM_API_KEY
        st.success("âœ… å¯†ç æ­£ç¡®ï¼å·²åŠ è½½ä»¤ç‰Œ")
    else:
        if user_password: st.error("âŒ å¯†ç é”™è¯¯")
        st.caption("æˆ–è€…æ‰‹åŠ¨è¾“å…¥ API Keyï¼š")
        api_key = st.text_input("Key", type="password", label_visibility="collapsed")

    st.markdown("---")
    st.header("âš™ï¸ API è®¾ç½®")
    # é»˜è®¤ä½¿ç”¨ä½ çš„é¦™æ¸¯ä¸­è½¬åœ°å€
    base_url = st.text_input("API åœ°å€", value="https://hk-api.gptbest.vip/v1")
    
    st.caption("ğŸ“ æ–‡æœ¬æ¨¡å‹ (DeepSeek)")
    text_model = st.text_input("Text Model", value="deepseek-chat", label_visibility="collapsed")
    
    st.caption("ğŸ–¼ï¸ å›¾ç‰‡æ¨¡å‹ (GPT-4o)")
    vision_model = st.text_input("Vision Model", value="gpt-4o-mini", label_visibility="collapsed")

# --- ğŸ—ï¸ åŠŸèƒ½æ ‡ç­¾é¡µ ---
tab1, tab2 = st.tabs(["ğŸ“ æ–‡æœ¬ç”Ÿæˆæç¤ºè¯", "ğŸ–¼ï¸ å›¾ç‰‡åæ¨æç¤ºè¯ (çœ‹å›¾)"])

# ==========================================
# ğŸ‘‰ æ ‡ç­¾ 1ï¼šæ–‡æœ¬ç”Ÿæˆ (åŒè¯­ + é«˜çº§é€‰é¡¹)
# ==========================================
with tab1:
    st.subheader("âœï¸ æè¿°ç”»é¢ï¼Œç”Ÿæˆ Prompt")
    user_input = st.text_area("ä½ æƒ³ç”»ä»€ä¹ˆï¼Ÿ", height=100, placeholder="ä¾‹å¦‚ï¼šä¸€åªç©¿ç€å®‡èˆªæœçš„çŒ«ï¼Œèµ›åšæœ‹å…‹é£æ ¼...")

    # åŸºç¡€é€‰é¡¹
    c1, c2 = st.columns(2)
    with c1: 
        ratio = st.selectbox("ç”»å¹…", ["--ar 16:9", "--ar 9:16", "--ar 1:1", "--ar 3:4", "--ar 4:3"])
    with c2: 
        mode = st.selectbox("æ¨¡å¼", ["æ ‡å‡†æ¨¡å¼ (MJ/SD)", "å»ºç­‘è®¾è®¡", "è‡ªç„¶è¯­è¨€ (Google)", "äºŒæ¬¡å…ƒ (Niji)", "å†™å®æ‘„å½±", "3Dæ¸²æŸ“"])

    # âœ¨âœ¨âœ¨ ã€å·²æ¢å¤ã€‘é«˜çº§é€‰é¡¹æŠ˜å é¢æ¿ âœ¨âœ¨âœ¨
    with st.expander("ğŸ¨ ç‚¹å‡»å±•å¼€ï¼šé«˜çº§é€‰é¡¹ (å…‰çº¿ã€è§†è§’ã€æè´¨)"):
        col_a, col_b, col_c = st.columns(3)
        with col_a: 
            lighting = st.selectbox("ğŸ’¡ å…‰çº¿æ°›å›´", ["ä¸æŒ‡å®š", "è‡ªç„¶å…‰ (Natural)", "ç”µå½±çº§å¸ƒå…‰ (Cinematic)", "é»„é‡‘æ—¶åˆ» (Golden Hour)", "èµ›åšéœ“è™¹ (Neon)", "æŸ”å’Œå…‰ (Soft)", "æˆå‰§æ€§å…‰å½± (Dramatic)"])
        with col_b: 
            camera = st.selectbox("ğŸ“· é•œå¤´è§†è§’", ["ä¸æŒ‡å®š", "å¹¿è§’ (Wide Angle)", "å¾®è· (Macro)", "é¸Ÿç° (Aerial)", "äººè§†è§’åº¦ (Eye Level)", "é±¼çœ¼ (Fisheye)", "æ­£è§†å›¾ (Front View)"])
        with col_c: 
            material = st.selectbox("ğŸ§¶ æè´¨/æ¸²æŸ“", ["ä¸æŒ‡å®š", "è™šå¹»å¼•æ“5 (UE5)", "V-Rayæ¸²æŸ“", "ç£¨ç ‚è´¨æ„Ÿ (Matte)", "é‡‘å±å…‰æ³½ (Metallic)", "èƒ¶ç‰‡é¢—ç²’ (Film Grain)", "æ°´å½© (Watercolor)"])
        
        # è´Ÿé¢æç¤ºè¯
        negative_prompt = st.text_input("ğŸš« è´Ÿé¢æç¤ºè¯ (ä¸æƒ³å‡ºç°çš„å†…å®¹)", value="text, watermark, blurry, low quality, bad anatomy, ugly")

    # ğŸ”¥ æ ¸å¿ƒæŒ‡ä»¤ï¼šå¼ºåˆ¶åŒè¯­è¾“å‡º
    base_instruction = """
    You are an expert AI prompt engineer.
    IMPORTANT: You must output the result in exactly two parts using the specific format below:
    CN: [Here write the optimized description in Chinese]
    EN: [Here write the final English prompt]
    Do not add any other text or explanations.
    """
    
    # æ¨¡å¼å¾®è°ƒ
    mode_rules = {
        "æ ‡å‡†æ¨¡å¼ (MJ/SD)": "For EN: Output comma-separated keywords. Visual descriptors.",
        "å»ºç­‘è®¾è®¡": "For EN: Target Architectural Visualization. Add tags: ArchDaily style, V-Ray, 8k.",
        "è‡ªç„¶è¯­è¨€ (Google)": "For EN: Write a rich, descriptive English paragraph. Start with 'A photo of...'.",
        "äºŒæ¬¡å…ƒ (Niji)": "For EN: Anime style, cel shading, vibrant colors.",
        "å†™å®æ‘„å½±": "For EN: Photorealistic, 8k, shot on Sony A7RIV.",
        "3Dæ¸²æŸ“": "For EN: 3D render, blender, c4d, octane render."
    }
    
    sys_prompt = base_instruction + mode_rules.get(mode.split(" ")[0], "")

    if st.button("ğŸš€ ç”ŸæˆåŒè¯­æç¤ºè¯", type="primary"):
        if not api_key:
            st.error("è¯·å…ˆè¾“å…¥å¯†ç ï¼")
            st.stop()
        
        try:
            client = OpenAI(api_key=api_key, base_url=base_url)
            
            # ğŸ‘‡ æ‹¼æ¥é«˜çº§é€‰é¡¹ç»™ AI
            details = []
            if lighting != "ä¸æŒ‡å®š": details.append(f"å…‰çº¿: {lighting}")
            if camera != "ä¸æŒ‡å®š": details.append(f"è§†è§’: {camera}")
            if material != "ä¸æŒ‡å®š": details.append(f"æè´¨: {material}")
            
            # ç»„åˆæˆå®Œæ•´çš„è¯·æ±‚
            full_req = f"ç”¨æˆ·æè¿°: {user_input}ã€‚ é¢å¤–è¦æ±‚: {', '.join(details)}"

            with st.spinner('AI æ­£åœ¨åŒè¯­æ„æ€...'):
                resp = client.chat.completions.create(
                    model=text_model,
                    messages=[{"role": "system", "content": sys_prompt}, {"role": "user", "content": full_req}]
                )
                
                raw_content = resp.choices[0].message.content
                
                # è‡ªåŠ¨åˆ‡å‰²é€»è¾‘
                cn_text = "è§£æä¸­..."
                en_text = raw_content
                
                if "CN:" in raw_content and "EN:" in raw_content:
                    parts = raw_content.split("EN:")
                    cn_text = parts[0].replace("CN:", "").strip()
                    en_text = parts[1].strip()
                
                # æ‹¼æ¥æ¯”ä¾‹å’Œè´Ÿé¢è¯
                final_en = f"{en_text} {ratio}"
                # åªæœ‰éè‡ªç„¶è¯­è¨€æ¨¡å¼æ‰åŠ  --no å‚æ•°ï¼Œæˆ–è€…æ ¹æ®ä½ çš„ä¹ æƒ¯éƒ½åŠ ä¸Š
                if negative_prompt and "è‡ªç„¶è¯­è¨€" not in mode:
                    final_en += f" --no {negative_prompt}"

            # å±•ç¤ºç»“æœ
            st.markdown("### ğŸ‡¨ğŸ‡³ ä¸­æ–‡ä¼˜åŒ–æ„æ€")
            st.code(cn_text, language="text", wrap_lines=True)
            
            st.markdown("### ğŸ‡ºğŸ‡¸ è‹±æ–‡æç¤ºè¯ (ç›´æ¥å¤åˆ¶å»ç”»å›¾)")
            st.code(final_en, language="text", wrap_lines=True)
            
            st.caption(f"å·²åº”ç”¨è®¾ç½®ï¼š{lighting} | {camera} | {material}")
            
        except Exception as e:
            st.error(f"å‡ºé”™ï¼š{str(e)}")

# ==========================================
# ğŸ‘‰ æ ‡ç­¾ 2ï¼šå›¾ç‰‡åæ¨ (åŒè¯­ç‰ˆ)
# ==========================================
with tab2:
    st.subheader("ğŸ–¼ï¸ ä¸Šä¼ å›¾ç‰‡ï¼Œåæ¨ Prompt")
    uploaded_file = st.file_uploader("æ‹–å…¥å‚è€ƒå›¾", type=["jpg", "png"])
    
    if uploaded_file and st.button("ğŸ” å¼€å§‹åæ¨"):
        if not api_key:
            st.error("è¯·å…ˆè¾“å…¥å¯†ç ï¼")
            st.stop()
            
        try:
            client = OpenAI(api_key=api_key, base_url=base_url)
            img_b64 = encode_image(uploaded_file)
            
            with st.spinner('AI æ­£åœ¨çœ‹å›¾...'):
                resp = client.chat.completions.create(
                    model=vision_model,
                    messages=[{
                        "role": "user", 
                        "content": [
                            {"type": "text", "text": "åˆ†æè¿™å¼ å›¾ã€‚è¯·ä¸¥æ ¼æŒ‰æ­¤æ ¼å¼è¾“å‡ºï¼š\nCN: [ç”¨ä¸­æ–‡è¯¦ç»†æè¿°ç”»é¢å†…å®¹]\nEN: [Midjourneyæ ¼å¼çš„è‹±æ–‡å…³é”®è¯ï¼Œé€—å·åˆ†éš”]"},
                            {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{img_b64}"}}
                        ]
                    }]
                )
            
            raw_content = resp.choices[0].message.content
            
            # åˆ‡å‰²é€»è¾‘
            cn_text = "è§£æä¸­..."
            en_text = raw_content
            if "CN:" in raw_content and "EN:" in raw_content:
                parts = raw_content.split("EN:")
                cn_text = parts[0].replace("CN:", "").strip()
                en_text = parts[1].strip()
            
            c1, c2 = st.columns([1, 2])
            with c1: st.image(uploaded_file, width=150)
            with c2:
                st.markdown("**ğŸ‡¨ğŸ‡³ ä¸­æ–‡æè¿°**")
                st.code(cn_text, language="text", wrap_lines=True)
                st.markdown("**ğŸ‡ºğŸ‡¸ è‹±æ–‡ Prompt**")
                st.code(en_text, language="text", wrap_lines=True)
                
        except Exception as e:
            st.error(f"å‡ºé”™ï¼š{str(e)}")

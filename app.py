import streamlit as st
from openai import OpenAI
import base64

# 1. é¡µé¢è®¾ç½®
st.set_page_config(page_title="ğŸ¨ AI æç¤ºè¯é­”æ³•å¸ˆ Pro", page_icon="ğŸª„", layout="centered")
st.title("âœ¨ AI æç¤ºè¯é­”æ³•å¸ˆ Pro")

# --- ğŸ› ï¸ è¾…åŠ©å‡½æ•° ---
def encode_image(uploaded_file):
    return base64.b64encode(uploaded_file.getvalue()).decode('utf-8')

# --- ğŸ” èº«ä»½éªŒè¯é€»è¾‘ (å‡çº§ç‰ˆï¼šä½¿ç”¨ session_state ç¼“å­˜) ---
# åˆå§‹åŒ–å…¨å±€ Keyï¼Œé˜²æ­¢åˆ·æ–°ä¸¢å¤±
if "cached_api_key" not in st.session_state:
    st.session_state.cached_api_key = None

with st.sidebar:
    st.header("ğŸ” èº«ä»½éªŒè¯")
    
    # è·å–äº‘ç«¯é…ç½®
    SYSTEM_PASSWORD = st.secrets.get("APP_PASSWORD", None)
    SYSTEM_API_KEY = st.secrets.get("API_KEY", None)
    
    user_password = st.text_input("ğŸ”‘ è®¿é—®å¯†ç ", type="password", placeholder="è¾“å…¥å¯†ç ï¼Œè‡ªåŠ¨åŠ è½½ Key")
    
    # æ‰‹åŠ¨ Key è¾“å…¥æ¡†
    manual_key = st.text_input("æˆ–æ‰‹åŠ¨è¾“å…¥ Key", type="password", label_visibility="collapsed")

    # ğŸ”„ éªŒè¯é€»è¾‘æ ¸å¿ƒ
    if SYSTEM_PASSWORD and user_password == SYSTEM_PASSWORD:
        # å¦‚æœå¯†ç å¯¹ï¼Œä¸”äº‘ç«¯æœ‰ Keyï¼Œå°±å­˜å…¥ç¼“å­˜
        if SYSTEM_API_KEY:
            st.session_state.cached_api_key = SYSTEM_API_KEY
            st.success("âœ… å¯†ç æ­£ç¡®ï¼ä»¤ç‰Œå·²é”å®š")
        else:
            st.error("âš ï¸ å¯†ç æ­£ç¡®ï¼Œä½†äº‘ç«¯æœªé…ç½® API_KEYï¼è¯·æ£€æŸ¥ Secretsã€‚")
    elif manual_key:
        # å¦‚æœå¡«äº†æ‰‹åŠ¨ Keyï¼Œå­˜å…¥ç¼“å­˜
        st.session_state.cached_api_key = manual_key
    elif user_password and user_password != SYSTEM_PASSWORD:
        st.error("âŒ å¯†ç é”™è¯¯")

    st.markdown("---")
    st.header("âš™ï¸ API è®¾ç½®")
    base_url = st.text_input("API åœ°å€", value="https://hk-api.gptbest.vip/v1")
    st.caption("ğŸ“ æ–‡æœ¬æ¨¡å‹ (DeepSeek)")
    text_model = st.text_input("Text Model", value="deepseek-chat", label_visibility="collapsed")
    st.caption("ğŸ–¼ï¸ å›¾ç‰‡æ¨¡å‹ (GPT-4o)")
    vision_model = st.text_input("Vision Model", value="gpt-4o-mini", label_visibility="collapsed")

# --- ğŸ—ï¸ åŠŸèƒ½æ ‡ç­¾é¡µ ---
tab1, tab2 = st.tabs(["ğŸ“ æ–‡æœ¬ç”Ÿæˆæç¤ºè¯", "ğŸ–¼ï¸ å›¾ç‰‡åæ¨æç¤ºè¯ (çœ‹å›¾)"])

# ==========================================
# ğŸ‘‰ æ ‡ç­¾ 1ï¼šæ–‡æœ¬ç”Ÿæˆ (åŒè¯­ + é«˜çº§é€‰é¡¹)
# ==========================================
with tab1:
    st.subheader("âœï¸ æè¿°ç”»é¢ï¼Œç”Ÿæˆ Prompt")
    user_input = st.text_area("ä½ æƒ³ç”»ä»€ä¹ˆï¼Ÿ", height=100, placeholder="ä¾‹å¦‚ï¼šä¸€ä¸ªAecomè®¾è®¡çš„è¶…é«˜å±‚å»ºç­‘...")

    c1, c2 = st.columns(2)
    with c1: 
        ratio = st.selectbox("ç”»å¹…", ["--ar 16:9", "--ar 9:16", "--ar 1:1", "--ar 3:4", "--ar 4:3"])
    with c2: 
        mode = st.selectbox("æ¨¡å¼", ["å»ºç­‘è®¾è®¡", "æ ‡å‡†æ¨¡å¼ (MJ/SD)", "è‡ªç„¶è¯­è¨€ (Google)", "äºŒæ¬¡å…ƒ (Niji)", "å†™å®æ‘„å½±", "3Dæ¸²æŸ“"])

    # âœ¨ é«˜çº§é€‰é¡¹
    with st.expander("ğŸ¨ ç‚¹å‡»å±•å¼€ï¼šé«˜çº§é€‰é¡¹ (å…‰çº¿ã€è§†è§’ã€æè´¨)"):
        col_a, col_b, col_c = st.columns(3)
        with col_a: 
            lighting = st.selectbox("ğŸ’¡ å…‰çº¿æ°›å›´", ["ä¸æŒ‡å®š", "è‡ªç„¶å…‰ (Natural)", "ç”µå½±çº§å¸ƒå…‰ (Cinematic)", "é»„é‡‘æ—¶åˆ» (Golden Hour)", "èµ›åšéœ“è™¹ (Neon)", "æŸ”å’Œå…‰ (Soft)", "æˆå‰§æ€§å…‰å½± (Dramatic)"])
        with col_b: 
            camera = st.selectbox("ğŸ“· é•œå¤´è§†è§’", ["ä¸æŒ‡å®š", "å¹¿è§’ (Wide Angle)", "å¾®è· (Macro)", "é¸Ÿç° (Aerial)", "äººè§†è§’åº¦ (Eye Level)", "é±¼çœ¼ (Fisheye)", "æ­£è§†å›¾ (Front View)"])
        with col_c: 
            material = st.selectbox("ğŸ§¶ æè´¨/æ¸²æŸ“", ["ä¸æŒ‡å®š", "è™šå¹»å¼•æ“5 (UE5)", "V-Rayæ¸²æŸ“", "ç£¨ç ‚è´¨æ„Ÿ (Matte)", "é‡‘å±å…‰æ³½ (Metallic)", "èƒ¶ç‰‡é¢—ç²’ (Film Grain)", "æ°´å½© (Watercolor)"])
        negative_prompt = st.text_input("ğŸš« è´Ÿé¢æç¤ºè¯", value="text, watermark, blurry, low quality, bad anatomy, ugly")

    # ğŸ”¥ æ ¸å¿ƒæŒ‡ä»¤
    base_instruction = """
    You are an expert AI prompt engineer.
    IMPORTANT: You must output the result in exactly two parts using the specific format below:
    CN: [Here write the optimized description in Chinese]
    EN: [Here write the final English prompt]
    Do not add any other text or explanations.
    """
    
    mode_rules = {
        "æ ‡å‡†æ¨¡å¼ (MJ/SD)": "For EN: Output comma-separated keywords. Visual descriptors.",
        "å»ºç­‘è®¾è®¡": "For EN: Target Architectural Visualization. Add tags: ArchDaily style, V-Ray, 8k, hyper-realistic.",
        "è‡ªç„¶è¯­è¨€ (Google)": "For EN: Write a rich, descriptive English paragraph. Start with 'A photo of...'.",
        "äºŒæ¬¡å…ƒ (Niji)": "For EN: Anime style, cel shading, vibrant colors.",
        "å†™å®æ‘„å½±": "For EN: Photorealistic, 8k, shot on Sony A7RIV.",
        "3Dæ¸²æŸ“": "For EN: 3D render, blender, c4d, octane render."
    }
    
    sys_prompt = base_instruction + mode_rules.get(mode.split(" ")[0], "")

    if st.button("ğŸš€ ç”ŸæˆåŒè¯­æç¤ºè¯", type="primary"):
        # ğŸ‘‰ è¿™é‡Œæ”¹ç”¨äº† session_state æ¥æ£€æŸ¥ Keyï¼Œéå¸¸ç¨³å®š
        current_key = st.session_state.cached_api_key
        
        if not current_key:
            st.error("ğŸš¨ æ— æ³•è·å– API Keyï¼")
            st.warning("åŸå› å¯èƒ½æ˜¯ï¼š\n1. è¿˜æ²¡è¾“å…¥å¯†ç ã€‚\n2. å¯†ç æ­£ç¡®ä½†äº‘ç«¯ secrets é‡Œçš„ API_KEY æ˜¯ç©ºçš„ã€‚")
            st.stop()
        
        try:
            client = OpenAI(api_key=current_key, base_url=base_url)
            
            details = []
            if lighting != "ä¸æŒ‡å®š": details.append(f"å…‰çº¿: {lighting}")
            if camera != "ä¸æŒ‡å®š": details.append(f"è§†è§’: {camera}")
            if material != "ä¸æŒ‡å®š": details.append(f"æè´¨: {material}")
            
            full_req = f"ç”¨æˆ·æè¿°: {user_input}ã€‚ é¢å¤–è¦æ±‚: {', '.join(details)}"

            with st.spinner('AI æ­£åœ¨åŒè¯­æ„æ€...'):
                resp = client.chat.completions.create(
                    model=text_model,
                    messages=[{"role": "system", "content": sys_prompt}, {"role": "user", "content": full_req}]
                )
                
                raw_content = resp.choices[0].message.content
                
                cn_text = "è§£æä¸­..."
                en_text = raw_content
                
                if "CN:" in raw_content and "EN:" in raw_content:
                    parts = raw_content.split("EN:")
                    cn_text = parts[0].replace("CN:", "").strip()
                    en_text = parts[1].strip()
                
                final_en = f"{en_text} {ratio}"
                if negative_prompt and "è‡ªç„¶è¯­è¨€" not in mode:
                    final_en += f" --no {negative_prompt}"

            st.markdown("### ğŸ‡¨ğŸ‡³ ä¸­æ–‡ä¼˜åŒ–æ„æ€")
            st.code(cn_text, language="text", wrap_lines=True)
            
            st.markdown("### ğŸ‡ºğŸ‡¸ è‹±æ–‡æç¤ºè¯ (ç›´æ¥å¤åˆ¶)")
            st.code(final_en, language="text", wrap_lines=True)
            
        except Exception as e:
            st.error(f"å‡ºé”™ï¼š{str(e)}")

# ==========================================
# ğŸ‘‰ æ ‡ç­¾ 2ï¼šå›¾ç‰‡åæ¨ (åŒè¯­ç‰ˆ)
# ==========================================
with tab2:
    st.subheader("ğŸ–¼ï¸ ä¸Šä¼ å›¾ç‰‡ï¼Œåæ¨ Prompt")
    uploaded_file = st.file_uploader("æ‹–å…¥å‚è€ƒå›¾", type=["jpg", "png"])
    
    if uploaded_file and st.button("ğŸ” å¼€å§‹åæ¨"):
        current_key = st.session_state.cached_api_key
        
        if not current_key:
            st.error("ğŸš¨ è¯·å…ˆè¾“å…¥å¯†ç ï¼"); st.stop()
            
        try:
            client = OpenAI(api_key=current_key, base_url=base_url)
            img_b64 = encode_image(uploaded_file)
            
            with st.spinner('AI æ­£åœ¨çœ‹å›¾...'):
                resp = client.chat.completions.create(
                    model=vision_model,
                    messages=[{
                        "role": "user", 
                        "content": [
                            {"type": "text", "text": "åˆ†æè¿™å¼ å›¾ã€‚è¯·ä¸¥æ ¼æŒ‰æ­¤æ ¼å¼è¾“å‡ºï¼š\nCN: [ç”¨ä¸­æ–‡è¯¦ç»†æè¿°ç”»é¢å†…å®¹]\nEN: [Midjourneyæ ¼å¼çš„è‹±æ–‡å…³é”®è¯ï¼Œé€—å·åˆ†éš”]"},
                            {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{img_b64}"}}
                        ]
                    }]
                )
            
            raw_content = resp.choices[0].message.content
            
            cn_text = "è§£æä¸­..."
            en_text = raw_content
            if "CN:" in raw_content and "EN:" in raw_content:
                parts = raw_content.split("EN:")
                cn_text = parts[0].replace("CN:", "").strip()
                en_text = parts[1].strip()
            
            c1, c2 = st.columns([1, 2])
            with c1: st.image(uploaded_file, width=150)
            with c2:
                st.markdown("**ğŸ‡¨ğŸ‡³ ä¸­æ–‡æè¿°**")
                st.code(cn_text, language="text", wrap_lines=True)
                st.markdown("**ğŸ‡ºğŸ‡¸ è‹±æ–‡ Prompt**")
                st.code(en_text, language="text", wrap_lines=True)
                
        except Exception as e:
            st.error(f"å‡ºé”™ï¼š{str(e)}")

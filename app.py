import streamlit as st
from openai import OpenAI
import base64

# 1. é¡µé¢è®¾ç½®
st.set_page_config(page_title="ğŸ¨ AI æç¤ºè¯é­”æ³•å¸ˆ Pro", page_icon="ğŸª„", layout="centered")
st.title("âœ¨ AI æç¤ºè¯é­”æ³•å¸ˆ Pro")

# --- ğŸ› ï¸ è¾…åŠ©å‡½æ•° ---
def encode_image(uploaded_file):
    return base64.b64encode(uploaded_file.getvalue()).decode('utf-8')

# --- ğŸ” ä¾§è¾¹æ ï¼šæ ¸å¿ƒè®¾ç½®åŒº ---
with st.sidebar:
    st.header("ğŸ” èº«ä»½éªŒè¯")
    
    # ä»äº‘ç«¯ä¿é™©ç®±è¯»å–é…ç½®
    SYSTEM_PASSWORD = st.secrets.get("APP_PASSWORD", None)
    SYSTEM_API_KEY = st.secrets.get("API_KEY", None)

    api_key = None
    
    # 1. å¯†ç è¾“å…¥æ¡†
    user_password = st.text_input("ğŸ”‘ è®¿é—®å¯†ç ", type="password", placeholder="è¾“å…¥å¯†ç ï¼Œè‡ªåŠ¨åŠ è½½ Key")

    # 2. éªŒè¯é€»è¾‘
    if SYSTEM_PASSWORD and user_password == SYSTEM_PASSWORD:
        api_key = SYSTEM_API_KEY
        st.success("âœ… å¯†ç æ­£ç¡®ï¼å·²åŠ è½½ä»¤ç‰Œ")
    else:
        # å¦‚æœå¯†ç ä¸å¯¹ï¼Œæ˜¾ç¤ºæ‰‹åŠ¨è¾“å…¥æ¡†
        if user_password: st.error("âŒ å¯†ç é”™è¯¯")
        st.caption("æˆ–è€…æ‰‹åŠ¨è¾“å…¥ API Keyï¼š")
        api_key = st.text_input("Key", type="password", label_visibility="collapsed")

    st.markdown("---")
    st.header("âš™ï¸ API è®¾ç½®")
    
    # ğŸ‘‡ é‡ç‚¹ï¼šè¿™é‡Œé»˜è®¤å€¼æ”¹æˆäº†ä½ æˆªå›¾é‡Œçš„ã€é¦™æ¸¯è·¯çº¿ã€‘ï¼Œè®°å¾—åŠ  /v1
    base_url = st.text_input("API åœ°å€", value="https://hk-api.gptbest.vip/v1")
    
    st.caption("ğŸ“ æ–‡æœ¬æ¨¡å‹ (DeepSeek)")
    text_model = st.text_input("Text Model", value="deepseek-chat", label_visibility="collapsed")
    
    st.caption("ğŸ–¼ï¸ å›¾ç‰‡æ¨¡å‹ (GPT-4o)")
    vision_model = st.text_input("Vision Model", value="gpt-4o-mini", label_visibility="collapsed")

# --- ğŸ—ï¸ åŠŸèƒ½æ ‡ç­¾é¡µ ---
tab1, tab2 = st.tabs(["ğŸ“ æ–‡æœ¬ç”Ÿæˆæç¤ºè¯", "ğŸ–¼ï¸ å›¾ç‰‡åæ¨æç¤ºè¯ (çœ‹å›¾)"])

# ==========================================
# ğŸ‘‰ æ ‡ç­¾ 1ï¼šæ–‡æœ¬ç”Ÿæˆ
# ==========================================
with tab1:
    st.subheader("âœï¸ æè¿°ç”»é¢ï¼Œç”Ÿæˆ Prompt")
    user_input = st.text_area("ä½ æƒ³ç”»ä»€ä¹ˆï¼Ÿ", height=100, placeholder="ä¾‹å¦‚ï¼šä¸€åº§æµ·è¾¹çš„ç™½è‰²ç¾æœ¯é¦†ï¼Œæç®€é£æ ¼...")

    c1, c2 = st.columns(2)
    with c1: ratio = st.selectbox("ç”»å¹…", ["--ar 16:9", "--ar 9:16", "--ar 1:1", "--ar 3:4"])
    with c2: mode = st.selectbox("æ¨¡å¼", ["æ ‡å‡†æ¨¡å¼ (MJ/SD)", "å»ºç­‘è®¾è®¡", "è‡ªç„¶è¯­è¨€ (Google)", "äºŒæ¬¡å…ƒ (Niji)", "å†™å®æ‘„å½±", "3Dæ¸²æŸ“"])

    # ç®€åŒ–çš„ç³»ç»Ÿæç¤ºè¯
    prompts_map = {
        "æ ‡å‡†æ¨¡å¼ (MJ/SD)": "Translate to English. Output comma-separated keywords. Visual descriptors.",
        "å»ºç­‘è®¾è®¡": "Translate to English. Target: Architectural Visualization. Tags: ArchDaily style, V-Ray, 8k.",
        "è‡ªç„¶è¯­è¨€ (Google)": "Translate to a rich, descriptive English paragraph. No tags. Start with 'A photo of...'.",
        "äºŒæ¬¡å…ƒ (Niji)": "Translate to English. Anime style, cel shading, vibrant colors.",
        "å†™å®æ‘„å½±": "Translate to English. Photorealistic, 8k, shot on Sony A7RIV.",
        "3Dæ¸²æŸ“": "Translate to English. 3D render, blender, c4d, octane render."
    }
    
    if st.button("ğŸš€ ç”Ÿæˆæ–‡æœ¬æç¤ºè¯", type="primary"):
        if not api_key: st.error("è¯·å…ˆè¾“å…¥å¯†ç ï¼"); st.stop()
        try:
            client = OpenAI(api_key=api_key, base_url=base_url)
            sys_prompt = prompts_map.get(mode.split(" ")[0], prompts_map["æ ‡å‡†æ¨¡å¼ (MJ/SD)"])
            
            with st.spinner('AI æ­£åœ¨æ„æ€...'):
                resp = client.chat.completions.create(
                    model=text_model,
                    messages=[{"role": "system", "content": sys_prompt}, {"role": "user", "content": user_input}]
                )
                final = f"{resp.choices[0].message.content} {ratio}"
                
            st.code(final, language="text", wrap_lines=True)
        except Exception as e:
            st.error(f"å‡ºé”™ï¼š{e}")

# ==========================================
# ğŸ‘‰ æ ‡ç­¾ 2ï¼šå›¾ç‰‡åæ¨
# ==========================================
with tab2:
    st.subheader("ğŸ–¼ï¸ ä¸Šä¼ å›¾ç‰‡ï¼Œåæ¨ Prompt")
    uploaded_file = st.file_uploader("æ‹–å…¥å‚è€ƒå›¾", type=["jpg", "png"])
    
    if uploaded_file and st.button("ğŸ” å¼€å§‹åæ¨"):
        if not api_key: st.error("è¯·å…ˆè¾“å…¥å¯†ç ï¼"); st.stop()
        try:
            client = OpenAI(api_key=api_key, base_url=base_url)
            img_b64 = encode_image(uploaded_file)
            
            with st.spinner('AI æ­£åœ¨çœ‹å›¾...'):
                resp = client.chat.completions.create(
                    model=vision_model,
                    messages=[{
                        "role": "user", 
                        "content": [
                            {"type": "text", "text": "æè¿°è¿™å¼ å›¾çš„ä¸»ä½“ã€é£æ ¼ã€å…‰å½±ã€‚è¾“å‡ºè‹±æ–‡å…³é”®è¯ï¼Œé€—å·åˆ†éš”ã€‚"},
                            {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{img_b64}"}}
                        ]
                    }]
                )
            
            st.image(uploaded_file, width=200)
            st.code(resp.choices[0].message.content, language="text", wrap_lines=True)
        except Exception as e:
            st.error(f"å‡ºé”™ï¼š{e}")
